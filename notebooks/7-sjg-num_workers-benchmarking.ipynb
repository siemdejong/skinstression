{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VU cluster has 32 CPU cores, and therefore I hypothesize that 32 workers could be used for loading data using the pytorch DataLoader class.\n",
    "\n",
    "This file serves as a test for that, using data applicable to the research question and a version of DataSet class along with some data augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    "    Grayscale,\n",
    "    AugMix,\n",
    "    RandAugment,\n",
    "    FiveCrop,\n",
    "    RandomCrop,\n",
    "    AutoAugmentPolicy,\n",
    "    AutoAugment,\n",
    ")\n",
    "\n",
    "\n",
    "# from load_data import load_image_data, load_label_data\n",
    "\n",
    "\n",
    "class THGStrainStressDataset(Dataset[Any]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_data_dir: str,\n",
    "        folder: int,\n",
    "        targets: np.ndarray,\n",
    "        extension: str = \"bmp\",\n",
    "        data_transform=None,\n",
    "        target_transform=None,\n",
    "    ):\n",
    "        # header = 0, assume there is a header in the labels.csv file.\n",
    "        self._data = Path(root_data_dir) / str(folder)\n",
    "        self.group = folder\n",
    "        self.targets = targets\n",
    "        self.extension = extension\n",
    "        self.transform = data_transform\n",
    "        self.target_transform = target_transform\n",
    "        self._length = sum(1 for _ in os.listdir(self._data))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._length\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        # TODO: Make it work with z-stacks!!!\n",
    "        # https://stackoverflow.com/a/60176057\n",
    "        # Assuming images follow [0, n-1], so they can be accesed directly.\n",
    "        # data_path = self.data_dir / (str(int(self.labels[\"index\"].iloc[idx])) + \".tif\")\n",
    "        image = Image.open(self._data / f\"{str(idx)}.{self.extension}\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.target_transform:\n",
    "            self.targets = self.target_transform(self.targets)\n",
    "\n",
    "        return image, self.targets\n",
    "\n",
    "\n",
    "# def create_dataloader(\n",
    "#     batch_size: int,\n",
    "#     data_path: Path,\n",
    "#     label_path: Path,\n",
    "#     shuffle: bool = True,\n",
    "# ) -> DataLoader[Any]:\n",
    "#     return DataLoader(\n",
    "#         dataset=THGStrainStressDataset(\n",
    "#             data_dir=data_path,\n",
    "#             label_path=label_path,\n",
    "#             data_transform=Compose(\n",
    "#                 [\n",
    "#                     RandomCrop(size=(258, 258)),\n",
    "#                     # Resize((258, 258)),\n",
    "#                     Grayscale(),\n",
    "#                     # AugMix(),\n",
    "#                     # RandAugment(num_ops=2),\n",
    "#                     ToTensor(),\n",
    "#                     # Lambda(lambda y: (y - y.mean()) / y.std()), # To normalize the image.\n",
    "#                 ],\n",
    "#             ),\n",
    "#         ),\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle=shuffle,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torchvision.transforms import Compose, Resize, Grayscale, ToTensor\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "data_transform = Compose(\n",
    "    [\n",
    "        # RandomCrop(size=(258, 258)),\n",
    "        Resize((258, 258)),\n",
    "        Grayscale(),\n",
    "        # AugMix(),\n",
    "        # RandAugment(num_ops=2),\n",
    "        ToTensor(),\n",
    "        # Lambda(lambda y: (y - y.mean()) / y.std()), # To normalize the image.\n",
    "    ]\n",
    ")\n",
    "\n",
    "datasets = []\n",
    "groups = []\n",
    "for _, labels in pd.read_csv('../data/z-stacks/sigmoid_labels.csv').iterrows():\n",
    "\n",
    "    folder = int(labels[\"index\"])\n",
    "    targets = labels[[\"A\", \"h\", \"slope\", \"C\"]].to_numpy(dtype=float)\n",
    "\n",
    "    if not (Path('../data/z-stacks/') / str(folder)).is_dir():\n",
    "        continue\n",
    "\n",
    "    dataset = THGStrainStressDataset(\n",
    "        root_data_dir='../data/z-stacks/',\n",
    "        folder=folder,\n",
    "        targets=targets,\n",
    "        data_transform=data_transform,\n",
    "    )\n",
    "    datasets.append(dataset)\n",
    "    groups.extend([folder] * len(dataset))\n",
    "\n",
    "groups = np.array(groups)\n",
    "dataset = ConcatDataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pin_memory is True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:11.696817874908447 second, num_workers=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:10.787748098373413 second, num_workers=21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:10.748571634292603 second, num_workers=22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:10.972535371780396 second, num_workers=23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:10.998663425445557 second, num_workers=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:11.005809783935547 second, num_workers=25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:11.182546138763428 second, num_workers=26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:11.199867010116577 second, num_workers=27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:11.575569152832031 second, num_workers=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:11.587659358978271 second, num_workers=29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:11.645626068115234 second, num_workers=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:10.828525304794312 second, num_workers=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.68s/it]\n",
      "/scistor/guest/sjg203/.conda/envs/stress-strain/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 33 worker processes in total. Our suggested max number of worker in current system is 32, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:10.72502064704895 second, num_workers=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.72s/it]\n",
      "/scistor/guest/sjg203/.conda/envs/stress-strain/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 34 worker processes in total. Our suggested max number of worker in current system is 32, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:10.866923093795776 second, num_workers=33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:16<00:00,  4.01s/it]\n",
      "/scistor/guest/sjg203/.conda/envs/stress-strain/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 35 worker processes in total. Our suggested max number of worker in current system is 32, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:16.059099912643433 second, num_workers=34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:20<00:00,  5.20s/it]\n",
      "/scistor/guest/sjg203/.conda/envs/stress-strain/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 36 worker processes in total. Our suggested max number of worker in current system is 32, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:20.79282021522522 second, num_workers=35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.80s/it]\n",
      "/scistor/guest/sjg203/.conda/envs/stress-strain/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 37 worker processes in total. Our suggested max number of worker in current system is 32, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:11.189171552658081 second, num_workers=36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.80s/it]\n",
      "/scistor/guest/sjg203/.conda/envs/stress-strain/lib/python3.9/site-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 38 worker processes in total. Our suggested max number of worker in current system is 32, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish with:11.191312074661255 second, num_workers=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:04<00:12,  4.16s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/scistor/guest/sjg203/projects/thg-strain-stress/notebooks/7-sjg-num_workers-benchmarking.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2242415a4953227d/scistor/guest/sjg203/projects/thg-strain-stress/notebooks/7-sjg-num_workers-benchmarking.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2242415a4953227d/scistor/guest/sjg203/projects/thg-strain-stress/notebooks/7-sjg-num_workers-benchmarking.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m5\u001b[39m)):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2242415a4953227d/scistor/guest/sjg203/projects/thg-strain-stress/notebooks/7-sjg-num_workers-benchmarking.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2242415a4953227d/scistor/guest/sjg203/projects/thg-strain-stress/notebooks/7-sjg-num_workers-benchmarking.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2242415a4953227d/scistor/guest/sjg203/projects/thg-strain-stress/notebooks/7-sjg-num_workers-benchmarking.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/.conda/envs/stress-strain/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/stress-strain/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/stress-strain/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1315\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m   1314\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m-> 1315\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1316\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1317\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/stress-strain/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1151\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1164\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1165\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/stress-strain/lib/python3.9/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[1;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/.conda/envs/stress-strain/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    317\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "pin_memory = True\n",
    "print('pin_memory is', pin_memory)\n",
    "\n",
    "for num_workers in range(20, 40, 1): \n",
    "    train_loader = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=30, num_workers=num_workers, pin_memory=pin_memory)\n",
    "    start = time.time()\n",
    "    for epoch in tqdm(range(1, 5)):\n",
    "        for i, data in enumerate(train_loader):\n",
    "            pass\n",
    "    end = time.time()\n",
    "    print(\"Finish with:{} second, num_workers={}\".format(end - start, num_workers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pin_memory is True\n",
    "\n",
    "\n",
    "100%|██████████| 4/4 [00:23<00:00,  5.78s/it]\n",
    "\n",
    "Finish with:23.138214349746704 second, num_workers=5\n",
    "\n",
    "100%|██████████| 4/4 [00:20<00:00,  5.17s/it]\n",
    "\n",
    "Finish with:20.68344020843506 second, num_workers=6\n",
    "\n",
    "100%|██████████| 4/4 [00:18<00:00,  4.51s/it]\n",
    "\n",
    "Finish with:18.05572271347046 second, num_workers=7\n",
    "\n",
    "100%|██████████| 4/4 [00:16<00:00,  4.09s/it]\n",
    "\n",
    "Finish with:16.365644693374634 second, num_workers=8\n",
    "\n",
    "100%|██████████| 4/4 [00:15<00:00,  3.76s/it]\n",
    "\n",
    "Finish with:15.046205043792725 second, num_workers=9\n",
    "\n",
    "100%|██████████| 4/4 [00:14<00:00,  3.69s/it]\n",
    "\n",
    "Finish with:14.744060516357422 second, num_workers=10\n",
    "\n",
    "100%|██████████| 4/4 [00:13<00:00,  3.44s/it]\n",
    "\n",
    "Finish with:13.76044750213623 second, num_workers=11\n",
    "\n",
    "100%|██████████| 4/4 [00:14<00:00,  3.51s/it]\n",
    "\n",
    "Finish with:14.033259630203247 second, num_workers=12\n",
    "\n",
    "100%|██████████| 4/4 [00:12<00:00,  3.15s/it]\n",
    "\n",
    "Finish with:12.621521472930908 second, num_workers=13\n",
    "\n",
    "100%|██████████| 4/4 [00:12<00:00,  3.22s/it]\n",
    "\n",
    "Finish with:12.886996269226074 second, num_workers=14\n",
    "\n",
    "100%|██████████| 4/4 [00:12<00:00,  3.17s/it]\n",
    "\n",
    "Finish with:12.667302370071411 second, num_workers=15\n",
    "\n",
    "100%|██████████| 4/4 [00:11<00:00,  2.96s/it]\n",
    "\n",
    "Finish with:11.828012943267822 second, num_workers=16\n",
    "\n",
    "100%|██████████| 4/4 [00:11<00:00,  2.95s/it]\n",
    "\n",
    "Finish with:11.805269718170166 second, num_workers=17\n",
    "\n",
    "100%|██████████| 4/4 [00:11<00:00,  2.91s/it]\n",
    "\n",
    "Finish with:11.644353151321411 second, num_workers=18\n",
    "\n",
    "100%|██████████| 4/4 [00:11<00:00,  2.85s/it]Finish with:11.383978605270386 second, num_workers=19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('stress-strain': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fd9d29be4be53d2a8266d7710f981b13e49e93ff435830c894f457b625c5065"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
