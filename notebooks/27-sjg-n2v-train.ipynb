{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import all our dependencies.\n",
    "from n2v.models import N2VConfig, N2V\n",
    "import numpy as np\n",
    "from csbdeep.utils import plot_history\n",
    "from n2v.utils.n2v_utils import manipulate_val_data\n",
    "from n2v.internals.N2V_DataGenerator import N2V_DataGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create our DataGenerator-object.\n",
    "# It will help us load data and extract patches for training and validation.\n",
    "datagen = N2V_DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will load all the '.png' files from the 'data' directory. In our case it is only one.\n",
    "# The function will return a list of images (numpy arrays).\n",
    "# In the 'dims' parameter we specify the order of dimensions in the image files we are reading:\n",
    "# 'C' stands for channels (color)\n",
    "imgs = datagen.load_imgs_from_directory(directory=\"../data/grayscale/z-stacks/1/\", filter='*.bmp', dims='YX')\n",
    "\n",
    "# Let's look at the shape of the image\n",
    "print('shape of loaded images: ',imgs[0].shape)\n",
    "# The function automatically added an extra dimension to the image.\n",
    "# It is used to hold a potential stack of images, such as a movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the image.\n",
    "# We have to remove the added extra dimension to display it as 2D image.\n",
    "plt.figure(figsize=(32,16))\n",
    "plt.imshow(imgs[0][0,:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we extract patches for training and validation.\n",
    "# The parameter 'shape' defines the size of these patches.\n",
    "patch_shape=(64,64)\n",
    "patches = datagen.generate_patches_from_list(imgs, shape=patch_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patches are created so they do not overlap.\n",
    "# (Note: this is not the case if you specify a number of patches. See the docstring for details!)\n",
    "# Non-overlapping patches enable us to split them into a training and validation set.\n",
    "split = int(np.floor(patches.shape[0]*0.80))\n",
    "X = patches[:split]\n",
    "X_val = patches[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at two patches.\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X[0,...])\n",
    "plt.title('Training Patch')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(X_val[0,...])\n",
    "plt.title('Validation Patch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_steps_per_epoch is set to (number of training patches)/(batch size), like this each training patch \n",
    "# is shown once per epoch. \n",
    "config = N2VConfig(X, unet_kern_size=3, \n",
    "                   unet_n_first=64, unet_n_depth=3, train_steps_per_epoch=int(X.shape[0]/128), train_epochs=200, train_loss='mse', \n",
    "                   batch_norm=True, train_batch_size=128, n2v_perc_pix=0.198, n2v_patch_shape=(64, 64), \n",
    "                   n2v_manipulator='median', n2v_neighborhood_radius=5, single_net_per_channel=False,\n",
    "                   blurpool=True, skip_skipone=True, unet_residual=False)\n",
    "\n",
    "# Let's look at the parameters stored in the config-object.\n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a name used to identify the model --> change this to something sensible!\n",
    "model_name = 'n2v_sample_1'\n",
    "# the base directory in which our model will live\n",
    "basedir = 'outputs/n2v/models'\n",
    "# We are now creating our network model.\n",
    "model = N2V(config, model_name, basedir=basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.train(X, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(history.history.keys())))\n",
    "plt.figure(figsize=(16,5))\n",
    "plot_history(history,['loss','val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export_TF(name='Noise2Void - Skinstression - sample 1', \n",
    "                description='This is the N2V for the skinstression project for sample 1', \n",
    "                authors=[\"Siem\"],\n",
    "                test_img=X_val[0], axes='YX',\n",
    "                patch_shape=patch_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('stress-strain': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fd9d29be4be53d2a8266d7710f981b13e49e93ff435830c894f457b625c5065"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
