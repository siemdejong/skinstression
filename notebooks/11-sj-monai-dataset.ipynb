{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.data import ITKReader, ImageDataset, TiffFileWSIReader, ImageReader, Dataset, CSVDataset, DatasetFunc\n",
    "from monai.transforms import LoadImage\n",
    "from functools import partial\n",
    "from monai.data.image_reader import _copy_compatible_dict, _stack_images\n",
    "from monai.config import DtypeLike, NdarrayOrTensor, PathLike\n",
    "import torch\n",
    "from os.path import abspath\n",
    "from typing import Sequence\n",
    "from pathlib import Path\n",
    "import h5torch\n",
    "from time import time\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvips\n",
    "import numpy as np\n",
    "import zarr\n",
    "from monai.utils import MetaKeys, SpaceKeys, TraceKeys, ensure_tuple, optional_import, require_pkg\n",
    "import pandas as pd\n",
    "from monai.data.utils import pad_list_data_collate\n",
    "\n",
    "tifffile_imread, _ = optional_import(\"tifffile\", name=\"imread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from monai.config import PathLike\n",
    "from numpy import ndarray\n",
    "\n",
    "@require_pkg(\"tifffile\")\n",
    "class TiffFileReaderv1(ImageReader):\n",
    "    supported_suffixes = [\"tif\", \"tiff\", \"svs\"]\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def get_data(self, img) -> tuple[ndarray, dict]:\n",
    "        img_array: list[np.ndarray] = []\n",
    "        compatible_meta: dict = {}\n",
    "\n",
    "        for i in ensure_tuple(img):\n",
    "            print(i)\n",
    "            data = self._get_array_data(i)\n",
    "            img_array.append(data)\n",
    "            header = self._get_meta_dict(i)\n",
    "            header[MetaKeys.ORIGINAL_AFFINE] = self._get_affine(i, self.affine_lps_to_ras)\n",
    "            header[MetaKeys.SPACE] = SpaceKeys.RAS if self.affine_lps_to_ras else SpaceKeys.LPS\n",
    "            header[MetaKeys.AFFINE] = header[MetaKeys.ORIGINAL_AFFINE].copy()\n",
    "            header[MetaKeys.SPATIAL_SHAPE] = self._get_spatial_shape(i)\n",
    "            if self.channel_dim is None:  # default to \"no_channel\" or -1\n",
    "                header[MetaKeys.ORIGINAL_CHANNEL_DIM] = (\n",
    "                    float(\"nan\") if len(data.shape) == len(header[MetaKeys.SPATIAL_SHAPE]) else -1\n",
    "                )\n",
    "            else:\n",
    "                header[MetaKeys.ORIGINAL_CHANNEL_DIM] = self.channel_dim\n",
    "            _copy_compatible_dict(header, compatible_meta)\n",
    "\n",
    "        return _stack_images(img_array, compatible_meta), compatible_meta\n",
    "\n",
    "    def read(self, data, **kwargs):\n",
    "        img_ = []\n",
    "\n",
    "        filenames: Sequence[PathLike] = ensure_tuple(data)\n",
    "        kwargs_ = self.kwargs.copy()\n",
    "        kwargs_.update(kwargs)\n",
    "        for name in filenames:\n",
    "            name = f\"{name}\"\n",
    "            img_.append(tifffile.imread(name, **kwargs_))\n",
    "        return img_ if len(filenames) > 1 else img_[0]\n",
    "\n",
    "    def verify_suffix(self, filename):\n",
    "        if filename.endswith(self.supported_suffixes):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "@require_pkg(pkg_name=\"tifffile\")\n",
    "class TiffFileReader(ImageReader):\n",
    "\n",
    "    supported_suffixes = [\"tif\", \"tiff\"]\n",
    "    backend = \"tifffile\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def read(self, data: Sequence[PathLike] | PathLike | np.ndarray, **kwargs):\n",
    "        \"\"\"\n",
    "        Read whole slide image objects from given file or list of files.\n",
    "\n",
    "        Args:\n",
    "            data: file name or a list of file names to read.\n",
    "            kwargs: additional args that overrides `self.kwargs` for existing keys.\n",
    "\n",
    "        Returns:\n",
    "            whole slide image object or list of such objects.\n",
    "\n",
    "        \"\"\"\n",
    "        img_list: list = []\n",
    "\n",
    "        filenames: Sequence[PathLike] = ensure_tuple(data)\n",
    "        kwargs_ = self.kwargs.copy()\n",
    "        kwargs_.update(kwargs)\n",
    "        for filename in filenames:\n",
    "            store = tifffile_imread(filename, **kwargs_)\n",
    "            img = zarr.open(store, mode=\"r\")\n",
    "            img_list.append(img)\n",
    "\n",
    "        return img_list if len(filenames) > 1 else img_list[0]\n",
    "\n",
    "    def verify_suffix(self, filename):\n",
    "        if filename.endswith(self.supported_suffixes):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def get_data(self, img) -> tuple[ndarray, dict]:\n",
    "        # img = np.array(img)\n",
    "        img = torch.tensor(np.array(img))\n",
    "        return img, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename_or_obj': '../data/stacks/10.tif', affine: tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]], dtype=torch.float64)}\n",
      "1.0520861148834229\n"
     ]
    }
   ],
   "source": [
    "images = list(Path(\"../data/stacks/\").glob(\"*.tif\"))\n",
    "dataset = ImageDataset(images, reader=TiffFileReader(aszarr=True))\n",
    "dataset.loader.readers = [TiffFileReader(aszarr=True)]\n",
    "b = time()\n",
    "print(dataset[1].meta)\n",
    "print(time() - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<monai.data.image_reader.ITKReader object at 0x7fe38a930950>, <monai.data.image_reader.NumpyReader object at 0x7fe38a932c10>, <monai.data.image_reader.PILReader object at 0x7fe38a930790>, <monai.data.image_reader.ITKReader object at 0x7fe3b26eb150>]\n",
      "torch.Size([1000, 1000, 30])\n",
      "0.3076913356781006\n"
     ]
    }
   ],
   "source": [
    "images = list(Path(\"../data/stacks/\").glob(\"*.tif\"))\n",
    "dataset = ImageDataset(images, reader='ITKReader')\n",
    "print(dataset.loader.readers)\n",
    "b = time()\n",
    "print(dataset[0].shape)\n",
    "print(time() - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "\n",
    "\n",
    "class A(Dataset):\n",
    "    def __init__(self, data: Sequence, transform = None) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: input data to load and transform to generate dataset for model.\n",
    "            transform: a callable data transform on input data.\n",
    "\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, index: int | slice | Sequence[int]):\n",
    "        # store = tifffile.imread(self.data[index][\"img\"], aszarr=True)\n",
    "        # img = zarr.open(store)\n",
    "        # img = torch.tensor(np.array(img))\n",
    "        img = tifffile.imread(self.data[index][\"img\"])\n",
    "        img = torch.tensor(np.array(img))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = A([dict(img=images[i]) for i in range(len(images))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33558106422424316\n"
     ]
    }
   ],
   "source": [
    "b = time()\n",
    "x = a[0]\n",
    "print(time() - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.473780870437622\n"
     ]
    }
   ],
   "source": [
    "b = time()\n",
    "store = tifffile.imread(\"../data/stacks/1.tif\", aszarr=True)\n",
    "img = torch.tensor(zarr.open(store, mode=\"r\"))\n",
    "print(time() -b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.data import ImageDataset\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from typing import Sequence\n",
    "\n",
    "class SkinstressionDataset(ImageDataset):\n",
    "    def __init__(self, image_dir, curves_dir, df, variables, *args, **kwargs) -> None:\n",
    "        self.df = df\n",
    "        image_files = (Path(image_dir) / df[\"filename\"]).tolist()\n",
    "        self.curves_dir = Path(curves_dir)\n",
    "        assert isinstance(variables, list), \"no variables selected. E.g. variables=['a', 'k', 'xc']\"\n",
    "        labels = torch.tensor(df[list(variables)].to_numpy())\n",
    "        super().__init__(image_files=image_files, labels=labels, *args, **kwargs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = list(super().__getitem__(index))\n",
    "        sample[0] = sample[0].unsqueeze(0)  # Because the model expects a batch and color dimension, next to the 3D image.\n",
    "        sample_id = str(self.df.loc[index][\"sample_id\"])\n",
    "        df_curves = pd.read_csv(str(self.curves_dir / Path(sample_id).with_suffix(\".csv\")))\n",
    "        sample.append(df_curves[\"strain\"].to_numpy())\n",
    "        sample.append(df_curves[\"stress\"].to_numpy())\n",
    "        return tuple(sample)\n",
    "\n",
    "image_dir = \"../data/stacks/\"\n",
    "curves_dir = \"../data/curves/\"\n",
    "df = pd.read_csv(\"../data/stacks/params.csv\")\n",
    "df_persons = pd.read_csv(\"../data/stacks/sample_to_person.csv\")\n",
    "df = df.merge(df_persons, on=\"sample_id\")\n",
    "df[\"filename\"] = [str(index) + \".tif\" for index in df[\"sample_id\"]]\n",
    "df.columns = list(map(str.lower, df.columns))\n",
    "variables = [\"k\"]\n",
    "# variables = [\"a\", \"k\", \"xc\"]\n",
    "dataset = SkinstressionDataset(image_dir=image_dir, curves_dir=curves_dir, df=df, variables=variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(metatensor([[[[  0.,   3.,   4.,  ...,   9.,   1., 144.],\n",
       "           [  2.,   4.,   5.,  ...,   1.,   3., 127.],\n",
       "           [  0.,   2.,   2.,  ...,   2.,   0., 155.],\n",
       "           ...,\n",
       "           [ 12.,  11.,  14.,  ...,  21.,  24.,  94.],\n",
       "           [  6.,   6.,  11.,  ...,  29.,   9.,  85.],\n",
       "           [  0.,   8.,  14.,  ...,  18.,  25.,  91.]],\n",
       " \n",
       "          [[  3.,   3.,   7.,  ...,  12.,   0., 138.],\n",
       "           [  1.,   1.,   3.,  ...,   5.,   0., 114.],\n",
       "           [  3.,   2.,   6.,  ...,   7.,   2., 146.],\n",
       "           ...,\n",
       "           [  5.,  11.,  14.,  ...,  20.,  20.,  86.],\n",
       "           [ 10.,  11.,   7.,  ...,  22.,  20.,  86.],\n",
       "           [ 10.,   6.,  10.,  ...,  24.,  27.,  92.]],\n",
       " \n",
       "          [[  9.,   2.,   9.,  ...,   9.,   0., 134.],\n",
       "           [  0.,   0.,   8.,  ...,   2.,   0., 135.],\n",
       "           [  0.,   4.,   2.,  ...,   4.,   3., 131.],\n",
       "           ...,\n",
       "           [  6.,   6.,  10.,  ...,  12.,  15.,  79.],\n",
       "           [ 10.,  11.,   6.,  ...,  18.,  15.,  84.],\n",
       "           [ 11.,  10.,   9.,  ...,  19.,  21.,  95.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 11.,   6.,  10.,  ...,  12.,  20.,  79.],\n",
       "           [  8.,   5.,  10.,  ...,  14.,  16.,  92.],\n",
       "           [  8.,  17.,  15.,  ...,  29.,  20., 103.],\n",
       "           ...,\n",
       "           [ 46.,  48.,  56.,  ...,  60.,  52.,  48.],\n",
       "           [ 39.,  54.,  58.,  ...,  51.,  60.,  51.],\n",
       "           [ 49.,  50.,  36.,  ...,  59.,  46.,  60.]],\n",
       " \n",
       "          [[ 10.,   5.,   8.,  ...,   9.,  24.,  95.],\n",
       "           [ 11.,  12.,  21.,  ...,  15.,  12., 101.],\n",
       "           [  8.,  11.,  12.,  ...,  16.,  21., 102.],\n",
       "           ...,\n",
       "           [ 40.,  48.,  55.,  ...,  62.,  51.,  50.],\n",
       "           [ 35.,  44.,  54.,  ...,  53.,  43.,  50.],\n",
       "           [ 44.,  51.,  38.,  ...,  45.,  59.,  62.]],\n",
       " \n",
       "          [[ 15.,   8.,   9.,  ...,  17.,  17.,  86.],\n",
       "           [ 13.,   6.,   5.,  ...,  12.,  15.,  98.],\n",
       "           [ 14.,   3.,  14.,  ...,  10.,  11., 108.],\n",
       "           ...,\n",
       "           [ 40.,  46.,  48.,  ...,  59.,  48.,  59.],\n",
       "           [ 37.,  56.,  57.,  ...,  45.,  54.,  51.],\n",
       "           [ 38.,  53.,  37.,  ...,  37.,  43.,  64.]]]]),\n",
       " tensor([28.9636], dtype=torch.float64),\n",
       " array([1.     , 1.05025, 1.06975, 1.09   , 1.11   , 1.12925, 1.1475 ,\n",
       "        1.16675, 1.18625, 1.20525, 1.2245 , 1.2435 , 1.262  , 1.2815 ,\n",
       "        1.30025]),\n",
       " array([0.       , 0.083125 , 0.04875  , 0.0328125, 0.093125 , 0.29375  ,\n",
       "        0.565    , 0.9421875, 1.365    , 1.79125  , 2.1546875, 2.4475   ,\n",
       "        2.7403125, 3.02625  , 3.22     ]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28.9636], dtype=torch.float64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_sort_ineligible_data(data: list[Path], csv_dataset):\n",
    "    eligible_sample_ids = [sample[\"sample_id\"] for sample in csv_dataset]\n",
    "    eligible_data = []\n",
    "    for _id in eligible_sample_ids:\n",
    "        for sample in data:\n",
    "            if int(sample.stem) != _id:\n",
    "                continue\n",
    "            eligible_data.append(sample)\n",
    "    return eligible_data\n",
    "\n",
    "target_dataset = CSVDataset([\"../data/stacks/params.csv\", \"../data/stacks/sample_to_person.csv\"])\n",
    "image_files = list(Path(\"../data/stacks\").glob(\"*.tif\"))\n",
    "image_files = DatasetFunc(image_files, filter_and_sort_ineligible_data, csv_dataset=target_dataset)\n",
    "img_dataset = ImageDataset(image_files, reader=\"ITKReader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'k']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(variables[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class SkinstressionDataset(Dataset):\n",
    "    def __init__(self, params, cols, sample_to_person, image_dir, curves_dir=None, suffix=\".tif\", reader=\"ITKReader\"):\n",
    "        \"\"\"\n",
    "        cols: list of params (str) to be selected from csv files in params. Order must correspond with model output.\n",
    "        \"\"\"\n",
    "        self.target_dataset = CSVDataset([params, sample_to_person], col_names=[\"sample_id\", \"person_id\"] + sorted(cols))\n",
    "        if curves_dir is not None:\n",
    "            curve_files = list(Path(curves_dir).glob(\"*.csv\"))\n",
    "            self.curves_datasets = []\n",
    "            for curve_file in curve_files:\n",
    "                curve_dataset = pd.read_csv(curve_file)\n",
    "                self.curves_datasets.append(curve_dataset)\n",
    "        else:\n",
    "            self.curves_datasets = None\n",
    "        image_files = list(Path(image_dir).glob(f\"*{suffix}\"))\n",
    "        image_files = DatasetFunc(image_files, self.filter_and_sort_ineligible_data, csv_dataset=self.target_dataset)\n",
    "        self.img_dataset = ImageDataset(image_files, reader=reader)\n",
    "        self.sample_info = self.pop_sample_infos()\n",
    "    \n",
    "    def pop_sample_infos(self):\n",
    "        sample_infos = []\n",
    "        for data in self.target_dataset:\n",
    "            sample_info = {\n",
    "                \"sample_id\": data.pop(\"sample_id\"),\n",
    "                \"person_id\": data.pop(\"person_id\"),\n",
    "            }\n",
    "            sample_infos.append(sample_info)\n",
    "        return sample_infos\n",
    "    \n",
    "    @staticmethod\n",
    "    def filter_and_sort_ineligible_data(data: list[Path], csv_dataset: CSVDataset):\n",
    "        eligible_sample_ids = map(lambda x: x[\"sample_id\"], csv_dataset)\n",
    "        eligible_data = []\n",
    "        for _id in eligible_sample_ids:\n",
    "            for sample in data:\n",
    "                if int(sample.stem) != _id:\n",
    "                    continue\n",
    "                eligible_data.append(sample)\n",
    "        return eligible_data\n",
    "\n",
    "    def __getitem__(self, index: int | slice | Sequence[int]):\n",
    "        out = {\n",
    "            \"img\": self.img_dataset[index],\n",
    "            \"target\": self.target_dataset[index],\n",
    "            \"sample_info\": self.sample_info[index],\n",
    "        }\n",
    "        if self.curves_datasets is not None:\n",
    "            out[\"curve\"] = self.curves_datasets[index]\n",
    "        return out\n",
    "\n",
    "skin = SkinstressionDataset(\"../data/stacks/params.csv\", [\"k\", \"A\"], \"../data/stacks/sample_to_person.csv\", \"../data/stacks/\", \"../data/curves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mskin\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_info\u001b[39m\u001b[38;5;124m\"\u001b[39m], skin[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m], skin[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename_or_obj\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'skin' is not defined"
     ]
    }
   ],
   "source": [
    "skin[0][\"sample_info\"], skin[0][\"target\"], skin[0][\"img\"].meta[\"filename_or_obj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skinstression.dataset import SkinstressionDataModule\n",
    "\n",
    "dm = SkinstressionDataModule(\"../data/stacks\", \"../data/stacks/params.csv\", \"../data/curves/\", \"../data/sample_to_person.csv\", [\"k\", \"A\"], batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 51/60 eligible samples\n",
      "train: 12 val: 5 test: 15\n"
     ]
    }
   ],
   "source": [
    "dm.setup(\"fit\")\n",
    "loader = dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stack(): argument 'tensors' (position 1) must be tuple of Tensors, not MetaTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_info\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/skinstression/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/skinstression/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/skinstression/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/z405155/skinstression/skinstression/dataset.py:371\u001b[0m, in \u001b[0;36mSkinstressionDataModule.collate_fn\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollate_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    370\u001b[0m     batch_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 371\u001b[0m     batch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     batch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mlist\u001b[39m(sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues())) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[1;32m    373\u001b[0m     batch_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_info\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_info\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m batch]\n",
      "\u001b[0;31mTypeError\u001b[0m: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not MetaTensor"
     ]
    }
   ],
   "source": [
    "batch = next(iter(loader))\n",
    "batch['sample_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skinstression.model import Skinstression\n",
    "\n",
    "model = Skinstression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "batch[\"img\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.data import ZipDataset\n",
    "\n",
    "class SkinstressionDataset(ZipDataset):\n",
    "    def __init__(self, params, cols, sample_to_person, image_dir, curve_dir=None, suffix=\".tif\", reader=\"ITKReader\"):\n",
    "        self.target_dataset = CSVDataset([str(params), str(sample_to_person)], col_names=[\"sample_id\", \"person_id\"] + sorted(cols))\n",
    "        if curve_dir is not None:\n",
    "            curve_files = list(Path(curve_dir).glob(\"*.csv\"))\n",
    "            self.curves_datasets = []\n",
    "            for curve_file in curve_files:\n",
    "                curve_dataset = pd.read_csv(curve_file)\n",
    "                curve_dataset = curve_dataset.to_numpy()\n",
    "                self.curves_datasets.append(curve_dataset)\n",
    "        else:\n",
    "            self.curves_datasets = None\n",
    "        image_files = list(Path(image_dir).glob(f\"*{suffix}\"))\n",
    "        image_files = DatasetFunc(image_files, self.filter_and_sort_ineligible_data, csv_dataset=self.target_dataset)\n",
    "        self.img_dataset = ImageDataset(image_files, reader=reader)\n",
    "        self.sample_info = self.pop_sample_infos()\n",
    "        super().__init__([self.img_dataset, self.target_dataset, self.sample_info, self.curves_datasets])\n",
    "    \n",
    "    def pop_sample_infos(self):\n",
    "        sample_infos = []\n",
    "        for data in self.target_dataset:\n",
    "            sample_info = {\n",
    "                \"sample_id\": data.pop(\"sample_id\"),\n",
    "                \"person_id\": data.pop(\"person_id\"),\n",
    "            }\n",
    "            sample_infos.append(sample_info)\n",
    "        return sample_infos\n",
    "    \n",
    "    @staticmethod\n",
    "    def filter_and_sort_ineligible_data(data: list[Path], csv_dataset: CSVDataset):\n",
    "        eligible_sample_ids = map(lambda x: x[\"sample_id\"], csv_dataset)\n",
    "        eligible_data = []\n",
    "        for _id in eligible_sample_ids:\n",
    "            for sample in data:\n",
    "                if int(sample.stem) != _id:\n",
    "                    continue\n",
    "                eligible_data.append(str(sample))\n",
    "        return eligible_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin = SkinstressionDataset(\"../data/stacks/params.csv\", [\"k\", \"A\"], \"../data/stacks/sample_to_person.csv\", \"../data/stacks/\", \"../data/curves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded\n",
      "torch.Size([31, 1000, 1000])\n",
      "padded\n",
      "torch.Size([31, 1000, 1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'img': metatensor([[[[ 3.,  0.,  0.,  ...,  4.,  0.,  1.],\n",
       "           [ 1.,  0.,  2.,  ...,  2.,  2.,  2.],\n",
       "           [ 0.,  1.,  0.,  ...,  0.,  1.,  1.],\n",
       "           ...,\n",
       "           [14., 16., 17.,  ...,  1.,  2.,  2.],\n",
       "           [15., 25., 22.,  ...,  1.,  1.,  0.],\n",
       "           [17., 11., 20.,  ...,  0.,  0.,  1.]],\n",
       " \n",
       "          [[ 1.,  0.,  0.,  ...,  1.,  1.,  0.],\n",
       "           [ 0.,  1.,  2.,  ...,  0.,  3.,  1.],\n",
       "           [ 0.,  0.,  1.,  ...,  2.,  0.,  1.],\n",
       "           ...,\n",
       "           [22., 18., 17.,  ...,  2.,  1.,  2.],\n",
       "           [17., 21., 14.,  ...,  1.,  2.,  0.],\n",
       "           [18., 14., 18.,  ...,  2.,  0.,  0.]],\n",
       " \n",
       "          [[ 1.,  3.,  0.,  ...,  2.,  0.,  2.],\n",
       "           [ 1.,  1.,  0.,  ...,  1.,  0.,  3.],\n",
       "           [ 1.,  1.,  1.,  ...,  4.,  3.,  2.],\n",
       "           ...,\n",
       "           [17., 18., 18.,  ...,  3.,  0.,  0.],\n",
       "           [24., 21., 12.,  ...,  0.,  0.,  1.],\n",
       "           [11., 16., 14.,  ...,  0.,  0.,  1.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[10.,  9.,  6.,  ...,  5.,  3.,  5.],\n",
       "           [ 7., 10.,  6.,  ...,  5.,  4.,  7.],\n",
       "           [ 7.,  8.,  2.,  ...,  8.,  2.,  6.],\n",
       "           ...,\n",
       "           [28., 26., 23.,  ...,  2.,  0.,  1.],\n",
       "           [28., 18., 29.,  ...,  0.,  0.,  1.],\n",
       "           [27., 17., 17.,  ...,  0.,  0.,  3.]],\n",
       " \n",
       "          [[ 6.,  9.,  7.,  ...,  7.,  8., 11.],\n",
       "           [ 8.,  5.,  4.,  ...,  7., 14.,  9.],\n",
       "           [ 4.,  6.,  5.,  ...,  3., 14., 13.],\n",
       "           ...,\n",
       "           [25., 18., 33.,  ...,  1.,  0.,  0.],\n",
       "           [32., 21., 30.,  ...,  0.,  0.,  0.],\n",
       "           [30., 33., 24.,  ...,  4.,  0.,  0.]],\n",
       " \n",
       "          [[12.,  9.,  7.,  ...,  7.,  4.,  4.],\n",
       "           [13., 10.,  8.,  ...,  7.,  6.,  7.],\n",
       "           [10.,  5.,  7.,  ...,  8.,  8.,  5.],\n",
       "           ...,\n",
       "           [30., 21., 19.,  ...,  1.,  0.,  0.],\n",
       "           [27., 24., 43.,  ...,  0.,  1.,  0.],\n",
       "           [17., 31., 19.,  ...,  1.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "         [[[ 0.,  1.,  1.,  ..., 14., 13., 21.],\n",
       "           [ 0.,  1.,  0.,  ..., 17., 24., 21.],\n",
       "           [ 0.,  1.,  0.,  ..., 19., 20., 18.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ..., 21., 19., 29.],\n",
       "           [ 0.,  0.,  0.,  ..., 20., 22., 22.],\n",
       "           [ 0.,  0.,  0.,  ..., 26., 24., 21.]],\n",
       " \n",
       "          [[ 0.,  1.,  1.,  ..., 26., 25., 19.],\n",
       "           [ 0.,  1.,  0.,  ..., 20., 22., 21.],\n",
       "           [ 0.,  0.,  0.,  ..., 19., 25., 20.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ..., 28., 22., 25.],\n",
       "           [ 0.,  0.,  0.,  ..., 29., 28., 24.],\n",
       "           [ 0.,  0.,  0.,  ..., 20., 20., 18.]],\n",
       " \n",
       "          [[ 0.,  0.,  0.,  ..., 18., 20., 27.],\n",
       "           [ 0.,  0.,  1.,  ..., 26., 25., 21.],\n",
       "           [ 1.,  0.,  0.,  ..., 17., 26., 17.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ..., 33., 37., 30.],\n",
       "           [ 0.,  0.,  0.,  ..., 27., 27., 27.],\n",
       "           [ 0.,  0.,  0.,  ..., 22., 24., 22.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 9., 12., 12.,  ...,  4.,  2.,  3.],\n",
       "           [12., 13., 15.,  ...,  3.,  1.,  3.],\n",
       "           [13., 14., 16.,  ...,  1.,  0.,  2.],\n",
       "           ...,\n",
       "           [ 4.,  3.,  3.,  ...,  0.,  1.,  2.],\n",
       "           [ 3.,  2.,  4.,  ...,  2.,  1.,  1.],\n",
       "           [ 3.,  5.,  5.,  ...,  1.,  1.,  1.]],\n",
       " \n",
       "          [[11., 11., 10.,  ...,  1.,  1.,  1.],\n",
       "           [10.,  9., 12.,  ...,  2.,  0.,  2.],\n",
       "           [ 8., 13., 12.,  ...,  1.,  4.,  0.],\n",
       "           ...,\n",
       "           [ 2.,  1.,  1.,  ...,  1.,  4.,  2.],\n",
       "           [ 3.,  2.,  4.,  ...,  1.,  2.,  0.],\n",
       "           [ 5.,  4.,  2.,  ...,  1.,  1.,  0.]],\n",
       " \n",
       "          [[11., 12.,  8.,  ...,  1.,  2.,  1.],\n",
       "           [10.,  9., 11.,  ...,  1.,  1.,  3.],\n",
       "           [ 8., 10., 14.,  ...,  2.,  1.,  3.],\n",
       "           ...,\n",
       "           [ 7.,  1.,  2.,  ...,  2.,  0.,  1.],\n",
       "           [ 3.,  4.,  1.,  ...,  1.,  5.,  0.],\n",
       "           [ 4.,  5.,  3.,  ...,  1.,  2.,  0.]]],\n",
       " \n",
       " \n",
       "         [[[ 0.,  2.,  0.,  ...,  2.,  1.,  3.],\n",
       "           [ 0.,  0.,  1.,  ...,  2.,  4.,  3.],\n",
       "           [ 1.,  1.,  0.,  ...,  7.,  4.,  3.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ...,  1.,  0.,  1.],\n",
       "           [ 0.,  0.,  0.,  ...,  2.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "          [[ 0.,  0.,  0.,  ...,  3.,  5.,  3.],\n",
       "           [ 0.,  1.,  0.,  ...,  4.,  6.,  5.],\n",
       "           [ 1.,  0.,  0.,  ...,  4.,  6.,  2.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ...,  1.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  1.,  1.,  1.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  1.,  1.]],\n",
       " \n",
       "          [[ 1.,  1.,  0.,  ...,  4.,  3.,  3.],\n",
       "           [ 1.,  1.,  0.,  ...,  5.,  4.,  2.],\n",
       "           [ 1.,  0.,  2.,  ...,  3.,  4.,  4.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  1.,  ...,  1.,  1.,  2.],\n",
       "           [ 0.,  0.,  0.,  ...,  2.,  1.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  2.,  1.,  0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6., 15.,  9.,  ...,  6.,  6.,  9.],\n",
       "           [15.,  9.,  9.,  ...,  5.,  8.,  8.],\n",
       "           [10., 11.,  7.,  ...,  6.,  7.,  6.],\n",
       "           ...,\n",
       "           [ 8.,  8., 12.,  ...,  0.,  0.,  0.],\n",
       "           [ 8., 11., 11.,  ...,  0.,  0.,  0.],\n",
       "           [ 8., 10., 14.,  ...,  0.,  1.,  0.]],\n",
       " \n",
       "          [[ 9.,  9., 10.,  ..., 10.,  6.,  7.],\n",
       "           [11.,  8.,  9.,  ...,  9.,  7.,  5.],\n",
       "           [10.,  9., 10.,  ...,  6.,  6.,  8.],\n",
       "           ...,\n",
       "           [ 8., 10., 10.,  ...,  0.,  0.,  0.],\n",
       "           [ 8.,  9., 10.,  ...,  0.,  0.,  1.],\n",
       "           [ 9.,  9.,  6.,  ...,  0.,  0.,  1.]],\n",
       " \n",
       "          [[10., 13.,  9.,  ...,  4.,  5.,  7.],\n",
       "           [10.,  9.,  6.,  ...,  6.,  5.,  5.],\n",
       "           [ 8.,  8.,  9.,  ...,  7.,  5.,  5.],\n",
       "           ...,\n",
       "           [11., 12.,  9.,  ...,  0.,  1.,  0.],\n",
       "           [10.,  9.,  6.,  ...,  0.,  0.,  0.],\n",
       "           [11.,  9.,  9.,  ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "         [[[ 0.,  1.,  0.,  ...,  1.,  0.,  1.],\n",
       "           [ 0.,  0.,  0.,  ...,  2.,  1.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  1.,  1.,  0.],\n",
       "           ...,\n",
       "           [ 2.,  2.,  1.,  ...,  2.,  1.,  1.],\n",
       "           [ 2.,  2.,  2.,  ...,  2.,  1.,  2.],\n",
       "           [ 3.,  1.,  1.,  ...,  1.,  0.,  1.]],\n",
       " \n",
       "          [[ 0.,  0.,  0.,  ...,  2.,  1.,  1.],\n",
       "           [ 0.,  0.,  0.,  ...,  2.,  2.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  1.,  1.,  1.],\n",
       "           ...,\n",
       "           [ 0.,  3.,  1.,  ...,  0.,  1.,  2.],\n",
       "           [ 0.,  1.,  2.,  ...,  1.,  2.,  1.],\n",
       "           [ 2.,  0.,  2.,  ...,  2.,  3.,  1.]],\n",
       " \n",
       "          [[ 0.,  0.,  0.,  ...,  1.,  1.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  1.,  1.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  1.,  1.,  2.],\n",
       "           ...,\n",
       "           [ 2.,  0.,  2.,  ...,  4.,  0.,  0.],\n",
       "           [ 1.,  1.,  0.,  ...,  1.,  0.,  2.],\n",
       "           [ 0.,  0.,  0.,  ...,  1.,  1.,  2.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.,  0.,  0.,  ...,  1.,  1.,  1.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  1.,  2.],\n",
       "           [ 0.,  0.,  0.,  ...,  2.,  2.,  1.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ...,  3.,  3.,  2.],\n",
       "           [ 0.,  0.,  1.,  ...,  2.,  3.,  2.],\n",
       "           [ 0.,  0.,  0.,  ...,  1.,  2.,  1.]],\n",
       " \n",
       "          [[ 0.,  0.,  0.,  ...,  3.,  0.,  1.],\n",
       "           [ 0.,  0.,  0.,  ...,  3.,  1.,  1.],\n",
       "           [ 1.,  0.,  0.,  ...,  2.,  0.,  1.],\n",
       "           ...,\n",
       "           [ 1.,  0.,  0.,  ...,  2.,  3.,  0.],\n",
       "           [ 0.,  0.,  1.,  ...,  4.,  1.,  5.],\n",
       "           [ 1.,  1.,  0.,  ...,  5.,  4.,  2.]],\n",
       " \n",
       "          [[ 0.,  0.,  0.,  ...,  0.,  1.,  2.],\n",
       "           [ 0.,  0.,  0.,  ...,  1.,  0.,  2.],\n",
       "           [ 0.,  0.,  0.,  ...,  2.,  1.,  1.],\n",
       "           ...,\n",
       "           [ 1.,  1.,  1.,  ...,  2.,  1.,  2.],\n",
       "           [ 0.,  0.,  0.,  ...,  1.,  2.,  2.],\n",
       "           [ 0.,  0.,  1.,  ...,  3.,  2.,  2.]]],\n",
       " \n",
       " \n",
       "         [[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "          [[ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  1.,  1.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "          [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.,  0.,  1.,  ...,  0.,  0.,  0.],\n",
       "           [ 1.,  0.,  1.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  1.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "          [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]],\n",
       " \n",
       "          [[ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]]]]),\n",
       " 'target': [{'A': 5.8810762382094, 'k': 24.949814880240133},\n",
       "  {'A': 3.6637352195486574, 'k': 21.96298150284788},\n",
       "  {'A': 2.4274528696190725, 'k': 17.765872097226683},\n",
       "  {'A': 3.146787124907819, 'k': 46.6717087788422},\n",
       "  {'A': 4.105054523470894, 'k': 29.315148105929325}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from monai.data import DataLoader\n",
    "import torch\n",
    "from monai.data import pad_list_data_collate\n",
    "from monai.transforms.croppad.functional import pad_func\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    # Get the maximum height and width among all images in the batch\n",
    "    max_height = np.max([item[0].shape[0] for item in batch])\n",
    "    max_width = np.max([item[0].shape[1] for item in batch])\n",
    "\n",
    "    # Pad each image to the maximum height and width\n",
    "    padded_images = []\n",
    "    for item in batch:\n",
    "        img = item[0].moveaxis(-1, 0)\n",
    "        pad_height = max_height - img.shape[1]\n",
    "        pad_width = max_width - img.shape[2]\n",
    "        padded_img = pad_func(img, ((0, 0), (0, pad_height), (0, pad_width)), {})\n",
    "        padded_images.append(padded_img)\n",
    "\n",
    "    # Stack the padded images\n",
    "    stacked_images = torch.stack(padded_images)\n",
    "\n",
    "    # Return the stacked images along with other items in the batch\n",
    "    return {'img': stacked_images, 'target': [item[1] for item in batch]}\n",
    "\n",
    "loader = DataLoader(skin, batch_size=5, collate_fn=custom_collate_fn)\n",
    "next(iter(loader))\n",
    "\n",
    "\n",
    "loader = DataLoader(skin, batch_size=5, collate_fn=custom_collate_fn)\n",
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded\n",
      "torch.Size([31, 1000, 1000])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'A': 5.8810762382094, 'k': 24.949814880240133},\n",
       " {'A': 3.6637352195486574, 'k': 21.96298150284788},\n",
       " {'A': 2.4274528696190725, 'k': 17.765872097226683},\n",
       " {'A': 3.146787124907819, 'k': 46.6717087788422},\n",
       " {'A': 4.105054523470894, 'k': 29.315148105929325}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skinstression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
